# dataset_slr

This dataset has been used in the research paper DeepASLR: A CNN based human computer interface for American Sign
Language recognition for hearing-impaired individuals

Ahmed KASAPBAŞI, Ahmed Eltayeb AHMED ELBUSHRA, Omar AL-HARDANEE, Arif YILMAZ,"DeepASLR: A CNN based human computer interface for American Sign Language recognition for hearing-impaired individuals", Computer Methods and Programs in Biomedicine Update, Volume 2, 2022, 100048, ISSN 2666-9900,https://doi.org/10.1016/j.cmpbup.2021.100048.

## Dataset features (as described in paper):
- contains images varying 0.5 m, 0.75 m and 1 m hand distance
- collected at different times of the day specifically to include different illumination conditions.
- the distance of the hand from the camera was reported to be fixed such as 0.5 m, 0.75 m or 1 m.
- both the Z and J letters are created by a small movement that represents the letter
- letters represented by static gesture at the start or end of the sign.
- required movement for these letters (Z and J) requires a separate neural network structure for achieving the recognition operation
- The dimensions of the images are 64 × 64
- 104,000 binary images
